---
title: "Take-home Exercise 1"
author: "Chang Fang Yu"
date-modified: "last-modified"
execute:
  echo: False
  eval: True
  warning: false
  freeze: true
---
# Ship Performace Clustering Analysis

##  Overview
In this exercise, we are going to utilize The Ship Performance Clustering Dataset to perform a clustering analysis. This dataset comproses numerical and categorical features representing different ship types, operational characteristics and other facters, enabling the segmentation of vessels based on key performance metrics, providing insights into their efficiency, cost-effectiveness and operational behaviors.

### Methodology and Tools
This analysis was conducted by R Studio, leveraging various statistical and visualization packages to facilitate data preprocessing, clustering, and result interpretation. The following R packages were employed:
```{R}
#|echo: TRUE
pacman::p_load(tidyverse, haven, knitr,
               patchwork, ggthemes, scales,
               ggridges, ggpubr, gganimate, ggraph,corrplot, ggstatsplot,
              plotly, caret, fastDummies, factoextra, cluster, Rtsne, ggfortify, BiocManager, rgl, ggthemes, colorspace, ggdist)
```
### Data Sources

[The Ship Performance Clustering](https://www.kaggle.com/datasets/jeleeladekunlefijabi/ship-performance-clustering-dataset/data)


## Data Pre-processing

```{R}
Ship <- read_csv("data/Ship_Performance_Dataset.csv")
```
### 2-1. Data First Glimpse by Glimpse() and Datatable
Glimpse() shows it consists of 2736 rows and 18 columns, including 1 date type, 5 categorical type, and 12 numerical type. 
By Datatable, We can check the detail of the dataset.

::: panel-tabset

#Glimpse
```{R}
#|echo: TRUE
cat('<div style="max-height: 200px; overflow-y: auto;">')
glimpse(Ship)
cat('</div>')
```
# Datatable

```{R}
cat('<div style="max-height: 200px; overflow-y: auto;">')
DT::datatable(Ship, class= "compact")
```
:::
### Data Sanity Check 
Checking for Duplicates and Missing Values
Duplicates
```{R}
Ship[duplicated(Ship),]
```
Missing Values
```{R}
sum(is.na(Ship))
```
## Exploratory Data Analysis(EDA)

::: panel-tabset

# The Distribution of Numerical Variables
```{R}
numerical_vars <- c("Speed_Over_Ground_knots", "Distance_Traveled_nm",
                    "Draft_meters", "Cargo_Weight_tons", "Turnaround_Time_hours", "Efficiency_nm_per_kWh","Seasonal_Impact_Score", "Weekly_Voyage_Count", "Average_Load_Percentage", "Engine_Power_kW", "Operational_Cost_USD", "Revenue_per_Voyage_USD" )


numerical_data <- Ship %>%
  select(all_of(numerical_vars))


ship_long_num <- Ship %>%
  pivot_longer(cols = all_of(numerical_vars), names_to = "Variable", values_to = "Value")

p <- ggplot(ship_long_num, aes(x = Value, fill = Variable)) +
  geom_histogram(alpha = 0.5, bins = 30, color = "black") +
  facet_wrap(~ Variable, scales = "free", ncol = 3) + 
  theme_minimal() +
  theme(
    plot.margin = margin(10, 10, 30, 10),
    axis.text.x = element_blank(),  # 隱藏 x 軸標籤
    legend.text = element_text(size = 7),
    panel.spacing = unit(2, "cm")
  ) +
  labs(title = "Histogram of Numeric Variables")

interactive_p <- ggplotly(p)


interactive_p
```
# Box Plot of Numerical Variables

```{R}

numerical_vars_1 <- c("Speed_Over_Ground_knots", "Engine_Power_kW", "Distance_Traveled_nm", 
                    "Cargo_Weight_tons", "Operational_Cost_USD", "Revenue_per_Voyage_USD", "Turnaround_Time_hours", "Efficiency_nm_per_kWh", "Seasonal_Impact_Score",
                    "Weekly_Voyage_Count", "Average_Load_Percentage")

ship_long <- Ship %>%
  pivot_longer(cols = all_of(numerical_vars_1), names_to = "Variable", values_to = "Value")

p <- ggplot(ship_long, aes(x = Variable, y = Value, fill = Variable)) +
  geom_boxplot(outlier.color = "red", outlier.size = 5) +
  facet_wrap(~ Variable, scales = "free", ncol = 3) +  
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1, size = 5),  
         
        legend.position = "bottom",
         panel.spacing = unit(1, "cm") ) +  
  labs(title = "Box Plot of Numerical Variables by Facet Wrap")

ggplotly(p)


```


# Distribution iof Categorical Variables
```{R}
categorical_vars <- c("Ship_Type", "Route_Type", "Engine_Type", 
                      "Maintenance_Status", "Weather_Condition")
Ship <- Ship %>%
  mutate(across(all_of(categorical_vars), as.factor))


ship_long_cat <- Ship %>%
  pivot_longer(cols = all_of(categorical_vars), names_to = "Variable", values_to = "Category")

p <- ggplot(ship_long_cat, aes(x = Category, fill = Category)) +
  geom_bar() +
  facet_wrap(~ Variable, scales = "free_x", ncol = 3) +  
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 9),  
    strip.text = element_text(size = 11),  
    legend.position = "none",  
    panel.spacing = unit(4, "cm")  
  ) +
  labs(title = "Distribution of Categorical Variables", x = "Category", y = "Count")

p_interactive <- ggplotly(p, tooltip = c("x", "y"))

p_interactive
```
:::
Insight: From the box plot, we can check there is no outliers existng in the data set.

### Variable Relationship

::: panel-tabset
# Operational Cost(USD) vs. Engine Type
```{R}
ggplot(Ship, 
       aes(x = Operational_Cost_USD, 
           y = Engine_Type)) +
  stat_halfeye(adjust = 0.5,
               justification = -0.2,
               .width = 0,
               point_colour = NA) +
  geom_boxplot(width = .20,
               outlier.shape = NA) +
  stat_dots(side = "left", 
            justification = 1.2, 
            binwidth = .5,
            dotsize = 2)

```
# Operational Cost(USD) vs. Route Type
```{R}
ggplot(Ship, 
       aes(x = Operational_Cost_USD, 
           y = Weather_Condition)) +
  stat_halfeye(adjust = 0.5,
               justification = -0.2,
               .width = 0,
               point_colour = NA) +
  geom_boxplot(width = .20,
               outlier.shape = NA) +
  stat_dots(side = "left", 
            justification = 1.2, 
            binwidth = .5,
            dotsize = 1.5) +
  coord_flip() +
  theme_economist()
```

# Revnue per Voyage(USD) vs. Route Type
```{R}
ggplot(Ship, 
       aes(x = Revenue_per_Voyage_USD, 
           y = Route_Type)) +
  stat_halfeye(adjust = 0.5,
               justification = -0.2,
               .width = 0,
               point_colour = NA) +
  geom_boxplot(width = .20,
               outlier.shape = NA) +
  stat_dots(side = "left", 
            justification = 1.2, 
            binwidth = .5,
            dotsize = 2)

```
# Revnue per Voyage(USD) vs. Ship Type
```{R}
ggplot(Ship, 
       aes(x = Revenue_per_Voyage_USD, 
           y = Ship_Type)) +
  stat_halfeye(adjust = 0.5,
               justification = -0.2,
               .width = 0,
               point_colour = NA) +
  geom_boxplot(width = .20,
               outlier.shape = NA) +
  stat_dots(side = "left", 
            justification = 1.2, 
            binwidth = .5,
            dotsize = 1.5) +
  coord_flip() +
  theme_economist()
```
:::

## Prepare Data for Clustering Analysis
### Data Preparing

1. Drop 'Date' variable.
```{R}
#|echo: TRUE
Ship <- Ship %>% select(-Date)
```

2. One-hot encoding 'Engine_Type, 'Route_Type', 'Ship_Type', 'Maintenance_Status'
```{R}
#|echo: TRUE
Ship_encoded <- dummy_cols(Ship, 
                           select_columns = c("Engine_Type", "Route_Type", "Ship_Type", "Weather_Condition", "Maintenance_Status"),
                           remove_first_dummy = TRUE, 
                           remove_selected_columns = TRUE)

```
```{R}

sum(is.na(Ship_encoded))
sum(sapply(Ship_encoded, function(x) sum(is.nan(x))))
sum(sapply(Ship_encoded, function(x) sum(is.infinite(x))))

```
4. Check Result
```{R}
#| include: True
str(Ship_encoded)  
summary(Ship_encoded)  
```
5. Perform Normalization
```{R}
numerical_vars <- c("Speed_Over_Ground_knots", "Engine_Power_kW", "Distance_Traveled_nm",
                    "Draft_meters", "Cargo_Weight_tons", "Operational_Cost_USD",
                    "Revenue_per_Voyage_USD", "Turnaround_Time_hours", "Efficiency_nm_per_kWh",
                    "Seasonal_Impact_Score", "Weekly_Voyage_Count", "Average_Load_Percentage")

Ship_scaled <- Ship_encoded 

Ship_scaled[numerical_vars] <- scale(Ship_scaled[numerical_vars])
```

```{R}

sum(is.na(Ship_scaled))
```
## Visualising Correlation Matrix
```{R}
ggstatsplot::ggcorrmat(
  data = Ship, 
  cor.vars = 1:11,
  ggcorrplot.args = list(outline.color = "black", 
                         hc.order = TRUE,
                         tl.cex = 10),
  title    = "Correlogram for Ship dataset",
)
```

## Perform Clustering Analysis

### Find appropriate K value
::: panel-tabset
# Elbow Method
```{R}
set.seed(123) 

wss <- function(k) {
  kmeans(Ship_scaled, centers = k, nstart = 25)$tot.withinss
}

k_values <- 1:10
wss_values <- map_dbl(k_values, wss)

plot(k_values, wss_values, type = "b", pch = 19, frame = FALSE,
     xlab = "Number of Clusters K", ylab = "Total Within Sum of Squares",
     main = "Elbow Method for Optimal K")
```
# Silhouette Method
```{R}
set.seed(123) 
silhouette_score <- function(k) {
  km_result <- kmeans(Ship_scaled, centers = k, nstart = 25)
  sil <- silhouette(km_result$cluster, dist(Ship_scaled))
  mean(sil[, 3])  
}

sil_values <- map_dbl(2:10, silhouette_score)

plot(2:10, sil_values, type = "b", pch = 19, frame = FALSE,
     xlab = "Number of Clusters K", ylab = "Average Silhouette Score",
     main = "Silhouette Method for Optimal K")
```
:::

Find the best k value =3

### Perform PCA

Result
```{R}

Ship_numeric <- Ship_scaled %>% select_if(is.numeric)

pca_result <- prcomp(Ship_numeric, center = TRUE, scale. = TRUE)

summary(pca_result)
```
Screeplot
```{R}
screeplot <- ggplot(data.frame(PC = 1:length(pca_result$sdev),
                               Variance = cumsum(pca_result$sdev^2 / sum(pca_result$sdev^2))),
                    aes(x = PC, y = Variance)) +
  geom_point() + geom_line() +
  labs(title = "Cumulative Variance Explained by PCA", x = "Principal Component", y = "Cumulative Variance") +
  theme_minimal()

print(screeplot)
```


### Perform Clustering Analysis
From the PCA results, we selected the top 20 components and transformed the data into a new dimension-reduced dataset.
K = 3
We only show PC4 vs. PC5 which has better clustering effect.

```{R}
library(ggplot2)
library(plotly)        # 交互式 2D 可视化
library(scatterplot3d) # Quarto 兼容的 3D 可视化
library(cluster)

pca_data <- as.data.frame(pca_result$x[, 1:20])

set.seed(123)

kmeans_result <- kmeans(pca_data, centers = 3, nstart = 25)
# 2D
pca_data$Cluster <- as.factor(kmeans_result$cluster)
p_2d <- ggplot(pca_data, aes(x = PC4, y = PC5, color = Cluster)) + 
  geom_point(alpha = 0.7) +
  labs(title = "K-Means Clustering on PCA Data (K=3)", 
       x = "Principal Component 4", 
       y = "Principal Component 5") +
  theme_minimal()

p_2d_plotly <- ggplotly(p_2d)

p_2d_plotly

# #D
p_3d_plotly <- plot_ly(
  data = pca_data, 
  x = ~PC3, 
  y = ~PC4, 
  z = ~PC5, 
  color = ~Cluster, 
  colors = c("red", "blue", "green"),  # 设定不同簇的颜色
  type = "scatter3d", 
  mode = "markers",
  marker = list(size = 3, opacity = 0.8)
) %>%
  layout(
    title = "K-Means Clustering in 3D PCA Space",
    scene = list(
      xaxis = list(title = "PC3"),
      yaxis = list(title = "PC4"),
      zaxis = list(title = "PC5")
    )
  )

p_3d_plotly

write.csv(pca_data, "PCA_KMeans_Clusters.csv", row.names = FALSE)
```

```{R}
#| include: True
class(pca_data)  
str(pca_data)
```


Next, by PCA Loading plot, we can interpret the importance of features in reducing dimensionality while retaining essential information.
The first 5 principal components (PCs) are selected ([, 1:5]), which means only the top five components are retained.

### PCA Loadings Heatmap
```{R}
#PCA Loadings Heatmap

library(ggplot2)
library(reshape2)

# K=3
loadings_matrix <- pca_result$rotation[, 1:5]


loadings_df <- as.data.frame(loadings_matrix)
loadings_df$Feature <- rownames(loadings_matrix)  
loadings_melt <- melt(loadings_df, id.vars = "Feature")  

ggplot(loadings_melt, aes(x = variable, y = Feature, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red") +
  labs(title = "PCA Loadings Heatmap (Top 3 PCs)", 
       x = "Principal Component", 
       y = "Feature") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


Next, we are going to figure out the characteristics of 3 cluster.

First, calculate the mean of each cluster in PCA.


```{R}

library(dplyr)
reconstructed_data <- as.data.frame(pca_data)
if (!"Cluster" %in% colnames(reconstructed_data)) {
  reconstructed_data$Cluster <- pca_data$Cluster  # 从 pca_data 复制 Cluster 列
}


# calculate the mean of Cluster 
numeric_summary <- reconstructed_data %>%
  group_by(Cluster) %>%
  summarise(across(where(is.numeric), list(mean = mean, sd = sd), na.rm = TRUE))

print(numeric_summary)
```
Below, we visualize the mean and standard deviation of each principal component (PC).
### Plot PC by mean and Std
```{R}
library(ggplot2)
library(reshape2)
library(dplyr)

top_20_features <- numeric_summary %>%
  select(Cluster, matches("^PC[1-9]|^PC1[0-9]|^PC20"))  # 选 PC1 到 PC20 的列

print(colnames(top_20_features))

numeric_melt <- melt(top_20_features, id.vars = "Cluster")

numeric_mean <- numeric_melt[grep("_mean$", numeric_melt$variable), ]
numeric_sd <- numeric_melt[grep("_sd$", numeric_melt$variable), ]


numeric_mean$variable <- gsub("_mean", "", numeric_mean$variable)
numeric_sd$variable <- gsub("_sd", "", numeric_sd$variable)


ggplot(numeric_mean, aes(x = variable, y = value, fill = Cluster)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(data = numeric_sd, aes(ymin = numeric_mean$value - value, ymax = numeric_mean$value + value),
                position = position_dodge(width = 0.9), width = 0.3) +
  labs(title = "Cluster Numerical Features with Error Bars", x = "Feature", y = "Mean Value") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10))


```

```{R}

pca_result <- prcomp(Ship_scaled, center = TRUE, scale. = TRUE)
pca_data <- as.data.frame(pca_result$x[, 1:20])  

set.seed(42)
kmeans_result <- kmeans(pca_data, centers = 3)

Ship_encoded$Cluster <- as.factor(kmeans_result$cluster)
```

### Distribution of categorial variables by Cluster 
Below is a visualization where we can observe the distribution of categorical variables in each cluster.


```{R}

set.seed(42)
kmeans_result <- kmeans(pca_data, centers = 3) 
Ship_encoded$Cluster <- as.factor(kmeans_result$cluster)  


category_means <- Ship_encoded %>%
  group_by(Cluster) %>%
  summarise(across(starts_with("Engine_Type") | starts_with("Route_Type") | 
                   starts_with("Ship_Type") | starts_with("Weather_Condition") | 
                   starts_with("Maintenance_Status"), mean))


category_melt <- pivot_longer(category_means, cols = -Cluster, names_to = "Category", values_to = "Proportion")

#  Stacked Bar Chart
ggplot(category_melt, aes(x = as.factor(Cluster), y = Proportion, fill = Category)) +
  geom_bar(stat = "identity", position = "fill") +  
  labs(title = "Categorical Feature Proportions by Cluster",
       x = "Cluster",
       y = "Proportion") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```




## Summary and Conclusion

## References

